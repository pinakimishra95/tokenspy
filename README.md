# tokenspy ğŸ”¥

<div align="center">

**You're spending $800/month on LLMs. Which function is burning it?**

*Find out in one line. No proxy. No signup. No traffic rerouting.*

[![PyPI version](https://img.shields.io/pypi/v/tokenspy.svg)](https://pypi.org/project/tokenspy/)
[![Tests](https://github.com/pinakimishra95/tokenspy/actions/workflows/tests.yml/badge.svg)](https://github.com/pinakimishra95/tokenspy/actions)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Zero dependencies](https://img.shields.io/badge/dependencies-zero-brightgreen.svg)](https://pypi.org/project/tokenspy/)

```bash
pip install tokenspy
```

</div>

---

## The Problem

You get an OpenAI invoice. It says **$800 this month**. You have no idea which function caused it.

```python
def run_pipeline(query):
    docs = fetch_and_summarize(query)    # â† costs $600?
    entities = extract_entities(docs)   # â† or this one?
    return generate_report(entities)    # â† or this one?
```

Langfuse and Helicone force you to reroute traffic through their proxy. Sign up. Configure. Break your local setup.

**tokenspy takes 1 line. No proxy. No signup. Runs entirely on your machine.**

---

## The Fix

```python
import tokenspy

@tokenspy.profile
def run_pipeline(query):
    docs = fetch_and_summarize(query)
    entities = extract_entities(docs)
    return generate_report(entities)

run_pipeline("Analyze Q3 earnings")
tokenspy.report()
```

---

## Output

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  tokenspy cost report                                                  â•‘
â•‘  total: $0.0523  Â·  18,734 tokens  Â·  3 calls                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                      â•‘
â•‘  fetch_and_summarize      $0.038  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  73%             â•‘
â•‘    â””â”€ gpt-4o               $0.038  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  73%            â•‘
â•‘       â””â”€ 12,000 tokens                                               â•‘
â•‘                                                                      â•‘
â•‘  generate_report          $0.011  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  21%            â•‘
â•‘    â””â”€ gpt-4o               $0.011  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  21%            â•‘
â•‘       â””â”€ 3,600 tokens                                                â•‘
â•‘                                                                      â•‘
â•‘  extract_entities         $0.003  â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   6%            â•‘
â•‘    â””â”€ gpt-4o-mini          $0.003  â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   6%            â•‘
â•‘       â””â”€ 3,134 tokens                                                â•‘
â•‘                                                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Optimization hints                                                  â•‘
â•‘                                                                      â•‘
â•‘  ğŸ”´ fetch_and_summarize [gpt-4o]                                     â•‘
â•‘     Switch to gpt-4o-mini â€” 94% cheaper  (~$540/month savings)      â•‘
â•‘                                                                      â•‘
â•‘  ğŸŸ¡ fetch_and_summarize [gpt-4o]                                     â•‘
â•‘     Avg input: 12,000 tokens. Trim context or limit retrieval.       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Now you know: `fetch_and_summarize` is burning 73% of your budget. Fix that one function, cut your bill by $540/month.**

---

## Quick Start

### Decorator (most common)

```python
import tokenspy

@tokenspy.profile
def summarize_docs(docs: list[str]) -> str:
    return openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": "\n".join(docs)}]
    ).choices[0].message.content

summarize_docs(my_docs)
tokenspy.report()            # prints flame graph to terminal
tokenspy.report("html")     # writes tokenspy_report.html, opens in browser
```

### Context Manager

```python
with tokenspy.session("research_task") as s:
    response = anthropic_client.messages.create(
        model="claude-haiku-4-5",
        messages=[{"role": "user", "content": query}]
    )

print(f"Cost:   {s.cost_str}")    # "$0.0012"
print(f"Tokens: {s.tokens}")      # 3,240
print(f"Calls:  {s.calls}")       # 1
```

### Programmatic Access

```python
data = tokenspy.stats()
# {
#   "total_cost_usd": 0.042,
#   "total_tokens": 15000,
#   "total_calls": 3,
#   "by_function": {"summarize_docs": 0.038, "generate_report": 0.004},
#   "by_model":    {"gpt-4o": 0.040, "gpt-4o-mini": 0.002},
#   "calls": [...],
# }
```

### Persistent Tracking Across Sessions

```python
# In your app startup:
tokenspy.init(persist=True)   # saves to ~/.tokenspy/usage.db

# Decorate as normal â€” costs accumulate across restarts
@tokenspy.profile
def my_agent(query):
    ...
```

---

## How It Works

tokenspy monkey-patches the SDK client **in-process** â€” the same technique used by `py-spy` and `line_profiler`:

```
Your Code
    â”‚
    â”œâ”€â”€ @tokenspy.profile â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ sets active function
    â”‚
    â””â”€â”€ openai_client.chat.completions.create(...)
                â”‚
                â””â”€â”€ tokenspy interceptor (in-process monkey-patch)
                        â”œâ”€â”€ calls original SDK method
                        â”œâ”€â”€ reads response.usage (tokens)
                        â”œâ”€â”€ looks up cost in built-in pricing table
                        â”œâ”€â”€ records: function Â· model Â· tokens Â· cost Â· duration
                        â””â”€â”€ returns response UNCHANGED to your code

tokenspy.report() â†’ renders flame graph from recorded data
```

**No proxy server. No HTTP interception. No environment variables. No configuration.**

Your code runs exactly as before. tokenspy just watches and keeps score.

---

## HTML Flame Graph

```python
tokenspy.report(format="html")
```

Opens a self-contained HTML file in your browser â€” zero JS dependencies, pure SVG:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  tokenspy â€” Total: $0.0523  (18,734 tokens)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  fetch_and_summarize  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  73%     â”‚
â”‚  generate_report      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      21%     â”‚
â”‚  extract_entities     â–ˆâ–ˆâ–ˆâ–ˆ                               6%     â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Model          â”‚  Cost   â”‚  %    â”‚ Input  â”‚ Output       â”‚   â”‚
â”‚  â”‚ gpt-4o         â”‚ $0.049  â”‚  94%  â”‚ 15,600 â”‚ 4,200        â”‚   â”‚
â”‚  â”‚ gpt-4o-mini    â”‚ $0.003  â”‚   6%  â”‚  3,134 â”‚    500       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Supported Providers

Automatically detected â€” nothing to configure:

| Provider | Package | Intercepted |
|---|---|---|
| **OpenAI** | `openai>=1.0` | `chat.completions.create` (sync + async) |
| **Anthropic** | `anthropic>=0.30` | `messages.create` (sync + async) |
| **Google** | `google-generativeai>=0.7` | `generate_content` |

---

## Built-in Pricing Table

30+ models, updated Feb 2026. No API call needed.

| Model | Input $/1M | Output $/1M |
|---|---|---|
| claude-opus-4-6 | $15.00 | $75.00 |
| claude-sonnet-4-6 | $3.00 | $15.00 |
| claude-haiku-4-5 | $0.80 | $4.00 |
| gpt-4o | $2.50 | $10.00 |
| gpt-4o-mini | $0.15 | $0.60 |
| o1 | $15.00 | $60.00 |
| gemini-1.5-pro | $1.25 | $5.00 |
| gemini-1.5-flash | $0.075 | $0.30 |

[â†’ Full pricing table](tokenspy/pricing.py)

---

## API Reference

| Symbol | Description |
|---|---|
| `@tokenspy.profile` | Decorator â€” profile all LLM calls inside the function |
| `tokenspy.session(name)` | Context manager â€” profile calls in a `with` block |
| `tokenspy.report()` | Print text flame graph to terminal |
| `tokenspy.report(format="html")` | Write + open HTML flame graph in browser |
| `tokenspy.stats()` | Return full breakdown as a dict |
| `tokenspy.reset()` | Clear all recorded calls |
| `tokenspy.init(persist=True)` | Enable SQLite persistence across sessions |

---

## Comparison

| | Langfuse | Helicone | LiteLLM Proxy | **tokenspy** |
|---|---|---|---|---|
| Requires proxy / gateway | âœ… yes | âœ… yes | âœ… yes | **âŒ no** |
| Requires signup | âœ… yes | âœ… yes | âŒ no | **âŒ no** |
| Local-first | âŒ no | âŒ no | âš¡ partial | **âœ… yes** |
| Zero dependencies | âŒ no | âŒ no | âŒ no | **âœ… yes** |
| Flame graph output | âŒ no | âŒ no | âŒ no | **âœ… yes** |
| `@decorator` API | âŒ no | âŒ no | âŒ no | **âœ… yes** |
| Optimization hints | âŒ no | âš¡ partial | âŒ no | **âœ… yes** |
| Works offline | âŒ no | âŒ no | âš¡ partial | **âœ… yes** |

---

## Roadmap

- [ ] Streaming response support (`stream=True`)
- [ ] Token budget alerts: `@tokenspy.profile(budget_usd=0.10)`
- [ ] LangChain / LangGraph integration
- [ ] CLI: `tokenspy history`, `tokenspy report`
- [ ] GitHub Actions annotation (cost diff per PR)
- [ ] Cost comparison across git commits

---

## Contributing

```bash
git clone https://github.com/pinakimishra95/tokenspy
cd tokenspy
pip install -e ".[dev]"
pytest tests/                # 59 tests, ~0.1s
```

Issues and PRs welcome â€” especially for new provider support and updated pricing.

---

## License

MIT Â© [Pinaki Mishra](https://github.com/pinakimishra95). See [LICENSE](LICENSE).

---

<div align="center">

**Star this repo if you're tired of mystery LLM invoices.** â­

[GitHub](https://github.com/pinakimishra95/tokenspy) Â· [PyPI](https://pypi.org/project/tokenspy/) Â· [Issues](https://github.com/pinakimishra95/tokenspy/issues)

</div>
